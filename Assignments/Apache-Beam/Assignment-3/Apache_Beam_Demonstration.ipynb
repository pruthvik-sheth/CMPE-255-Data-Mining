{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U9l9N-yVh_D",
        "outputId": "7cb932ef-7595-468d-db8c-1249bd4a0feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (3.10.11)\n",
            "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cloudpickle~=2.2.1 (from apache-beam)\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam)\n",
            "  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (4.23.0)\n",
            "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam)\n",
            "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.26.4)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (24.2)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam)\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (4.25.5)\n",
            "Collecting pydot<2,>=1.2.0 (from apache-beam)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2024.2)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam)\n",
            "  Downloading redis-5.2.0-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2024.9.11)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (4.12.2)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyarrow<17.0.0,>=3.0.0 (from apache-beam)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam) (0.6)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam) (3.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.21.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2024.8.30)\n",
            "Downloading apache_beam-2.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.2.0-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: crcmod, dill, hdfs, docopt\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31406 sha256=068b1089b26e80baa56256726e0fbd993b2b146759089e31312aa31db9a4d9af\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=6294f6882823f94786ed211bb1c73eae22157b3f86a9bf5b91dd1d07b31c2dc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=ed7dc79f799e4da960b492bb3af6d3e730131f90ea06ac7b8b841ccaee831906\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=869659596423596c92bada2e23ca589ba4bdace5e7693f807cc1c80eb015f0d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built crcmod dill hdfs docopt\n",
            "Installing collected packages: docopt, crcmod, zstandard, redis, pydot, pyarrow, objsize, jsonpickle, grpcio, fasteners, fastavro, dnspython, dill, cloudpickle, pymongo, hdfs, apache-beam\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.2\n",
            "    Uninstalling pydot-3.0.2:\n",
            "      Successfully uninstalled pydot-3.0.2\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 17.0.0\n",
            "    Uninstalling pyarrow-17.0.0:\n",
            "      Successfully uninstalled pyarrow-17.0.0\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 4.0.0\n",
            "    Uninstalling jsonpickle-4.0.0:\n",
            "      Successfully uninstalled jsonpickle-4.0.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.67.1\n",
            "    Uninstalling grpcio-1.67.1:\n",
            "      Successfully uninstalled grpcio-1.67.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.0\n",
            "    Uninstalling cloudpickle-3.1.0:\n",
            "      Successfully uninstalled cloudpickle-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2024.10.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache-beam-2.60.0 cloudpickle-2.2.1 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docopt-0.6.2 fastavro-1.9.7 fasteners-0.19 grpcio-1.65.5 hdfs-2.7.3 jsonpickle-3.4.2 objsize-0.7.0 pyarrow-16.1.0 pydot-1.4.2 pymongo-4.10.1 redis-5.2.0 zstandard-0.23.0\n"
          ]
        }
      ],
      "source": [
        "# Install Apache Beam\n",
        "!pip install apache-beam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Apache Beam Pipeline Example\n",
        "import apache_beam as beam\n",
        "\n",
        "# Define a basic Apache Beam pipeline\n",
        "with beam.Pipeline() as pipeline:\n",
        "    # Read from a sample list\n",
        "    input_data = pipeline | \"Create Data\" >> beam.Create([1, 2, 3, 4, 5])\n",
        "\n",
        "    # Apply a transformation (e.g., multiply each element by 2)\n",
        "    output_data = input_data | \"Multiply by 2\" >> beam.Map(lambda x: x * 2)\n",
        "\n",
        "    # Write the output to a text file\n",
        "    output_data | \"Write to File\" >> beam.io.WriteToText(\"output.txt\")\n",
        "\n",
        "print(\"Pipeline executed. Check 'output.txt' for the results.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "tJjmqcjBVq5Q",
        "outputId": "9a6a9c51-0206-4caa-92a1-ad5dd064669c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline executed. Check 'output.txt' for the results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Composite Transform Example\n",
        "class MultiplyAndFilter(beam.PTransform):\n",
        "    def expand(self, pcoll):\n",
        "        return (\n",
        "            pcoll\n",
        "            | \"Multiply by 3\" >> beam.Map(lambda x: x * 3)\n",
        "            | \"Filter Even Numbers\" >> beam.Filter(lambda x: x % 2 == 0)\n",
        "        )\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "    input_data = pipeline | \"Create Data\" >> beam.Create([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "    processed_data = input_data | \"Apply Composite Transform\" >> MultiplyAndFilter()\n",
        "    processed_data | \"Write Processed Data\" >> beam.io.WriteToText(\"composite_output.txt\")\n",
        "\n",
        "print(\"Composite Transform executed. Check 'composite_output.txt' for the results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFpQuAHTV4Lu",
        "outputId": "64d59a58-c731-4980-b20e-f0bda735c2fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Composite Transform executed. Check 'composite_output.txt' for the results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Triggers and Windowing Example\n",
        "import apache_beam as beam\n",
        "from apache_beam.transforms.window import FixedWindows\n",
        "\n",
        "# Define a sample dataset with timestamps\n",
        "sample_data = [\n",
        "    {\"event\": \"A\", \"timestamp\": 1},\n",
        "    {\"event\": \"B\", \"timestamp\": 2},\n",
        "    {\"event\": \"C\", \"timestamp\": 3},\n",
        "    {\"event\": \"D\", \"timestamp\": 6},\n",
        "    {\"event\": \"E\", \"timestamp\": 8},\n",
        "]\n",
        "\n",
        "# Apply a pipeline\n",
        "with beam.Pipeline() as pipeline:\n",
        "    (\n",
        "        pipeline\n",
        "        | \"Create Events\" >> beam.Create(sample_data)\n",
        "        | \"Add Timestamps\" >> beam.Map(lambda x: beam.window.TimestampedValue(x, x[\"timestamp\"]))\n",
        "        | \"Fixed Windowing\" >> beam.WindowInto(FixedWindows(3))  # 3-second fixed windows\n",
        "        | \"Extract Events\" >> beam.Map(lambda x: x[\"event\"])\n",
        "        | \"Write Windowed Output\" >> beam.io.WriteToText(\"windowed_output.txt\")\n",
        "    )\n",
        "\n",
        "print(\"Windowing example executed. Check 'windowed_output.txt' for results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89WNbHrJV9Gq",
        "outputId": "318e4a5e-3792-4588-e835-d6ba0419c168"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Windowing example executed. Check 'windowed_output.txt' for results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ParDo Example\n",
        "class SplitWords(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        return element.split()\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "    input_data = pipeline | \"Create Sentences\" >> beam.Create([\"Apache Beam is powerful\", \"Python is great\"])\n",
        "    words = input_data | \"Split into Words\" >> beam.ParDo(SplitWords())\n",
        "    words | \"Write Words\" >> beam.io.WriteToText(\"pardo_output.txt\")\n",
        "\n",
        "print(\"ParDo example executed. Check 'pardo_output.txt' for results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RTa7b-gWFzJ",
        "outputId": "45bc3f06-f674-4c27-b88d-fba2c6b8d1b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ParDo example executed. Check 'pardo_output.txt' for results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulated Streaming with ParDo\n",
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions, StandardOptions\n",
        "import time\n",
        "\n",
        "# Enable streaming mode\n",
        "pipeline_options = PipelineOptions()\n",
        "pipeline_options.view_as(StandardOptions).streaming = True\n",
        "\n",
        "# Custom DoFn to generate streaming events\n",
        "class GenerateEvents(beam.DoFn):\n",
        "    def process(self, _):\n",
        "        for i in range(5):  # Simulate 5 events\n",
        "            yield {\"event_id\": i, \"timestamp\": time.time()}\n",
        "            time.sleep(1)  # Simulate a 1-second delay between events\n",
        "\n",
        "with beam.Pipeline(options=pipeline_options) as pipeline:\n",
        "    (\n",
        "        pipeline\n",
        "        | \"Start Stream\" >> beam.Create([None])  # Dummy element to start the stream\n",
        "        | \"Generate Events\" >> beam.ParDo(GenerateEvents())\n",
        "        | \"Format Output\" >> beam.Map(lambda x: f\"Event ID: {x['event_id']} at {x['timestamp']}\")\n",
        "        | \"Write Streaming Output\" >> beam.io.WriteToText(\"streaming_output.txt\")\n",
        "    )\n",
        "\n",
        "print(\"Streaming example executed. Check 'streaming_output.txt' for results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFnN89bFWHkU",
        "outputId": "bb41147d-2bfc-447e-80b6-d67f59fc7da9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-f23c094b-6617-4375-85d9-e5d25cd12630.json']\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-f23c094b-6617-4375-85d9-e5d25cd12630.json']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming example executed. Check 'streaming_output.txt' for results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combined Features Example\n",
        "from apache_beam.transforms.window import FixedWindows\n",
        "from apache_beam.transforms.trigger import AfterProcessingTime, AccumulationMode\n",
        "\n",
        "# Custom DoFn to simulate event generation with timestamps\n",
        "class GenerateEventsWithTimestamps(beam.DoFn):\n",
        "    def process(self, _):\n",
        "        import random\n",
        "        import time\n",
        "        for i in range(10):  # Simulate 10 events\n",
        "            yield beam.window.TimestampedValue(\n",
        "                {\"event_id\": i, \"value\": random.randint(1, 100)},\n",
        "                time.time()\n",
        "            )\n",
        "            time.sleep(0.5)  # Simulate half-second intervals\n",
        "\n",
        "with beam.Pipeline(options=pipeline_options) as pipeline:\n",
        "    (\n",
        "        pipeline\n",
        "        | \"Start Stream\" >> beam.Create([None])  # Dummy element to kickstart the stream\n",
        "        | \"Generate Events\" >> beam.ParDo(GenerateEventsWithTimestamps())\n",
        "        | \"Fixed Windowing (5s)\" >> beam.WindowInto(\n",
        "            FixedWindows(5),  # Group events into 5-second windows\n",
        "            trigger=AfterProcessingTime(2),  # Emit results 2 seconds after processing\n",
        "            accumulation_mode=AccumulationMode.DISCARDING\n",
        "        )\n",
        "        | \"Process Events\" >> beam.Map(lambda x: f\"Event {x['event_id']} with value {x['value']}\")\n",
        "        | \"Write Results\" >> beam.io.WriteToText(\"combined_output.txt\")\n",
        "    )\n",
        "\n",
        "print(\"Combined example executed. Check 'combined_output.txt' for results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xI9aamjWNJD",
        "outputId": "dcec8aa3-f4fd-4fc7-c235-37df53c8a859"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-f23c094b-6617-4375-85d9-e5d25cd12630.json']\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-f23c094b-6617-4375-85d9-e5d25cd12630.json']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined example executed. Check 'combined_output.txt' for results.\n"
          ]
        }
      ]
    }
  ]
}