# Ensemble Methods and Decision Trees: From Scratch and Practical Demonstrations

## Overview

This repository contains implementations of classic ensemble methods and decision tree algorithms from scratch, as well as practical demonstrations of state-of-the-art gradient boosting techniques using popular libraries. Each method is showcased in a dedicated Colab notebook, accompanied by video walkthroughs.

---

## Contents

### Part 1: Implementations from Scratch

#### 1. Gradient Boosting Machine (GBM)

- **Notebook:** [GBM Implementation](https://colab.research.google.com/github/pruthvik-sheth/CMPE-255-Data-Mining/blob/main/Assignments/Decision-Trees/notebooks/Classic_GBM_from_scratch.ipynb)
- **Video Walkthrough:** [GBM Video Walkthrough](#)
- **Description:** Implements the GBM algorithm from scratch in Python, demonstrating its use for binary classification.

#### 2. Random Forest

- **Notebook:** [Random Forest Implementation](https://colab.research.google.com/github/pruthvik-sheth/CMPE-255-Data-Mining/blob/main/Assignments/Decision-Trees/notebooks/Random_Forest_from_scratch.ipynb)
- **Video Walkthrough:** [Random Forest Video Walkthrough](#)
- **Description:** A detailed implementation of the Random Forest algorithm from scratch, illustrating its ensemble learning approach for classification.

#### 3. AdaBoost

- **Notebook:** [AdaBoost Implementation](https://colab.research.google.com/github/pruthvik-sheth/CMPE-255-Data-Mining/blob/main/Assignments/Decision-Trees/notebooks/Ada_Boost_from_scratch.ipynb)
- **Video Walkthrough:** [AdaBoost Video Walkthrough](#)
- **Description:** Demonstrates the AdaBoost algorithm from scratch, highlighting its iterative boosting mechanism.

#### 4. Decision Trees

- **Notebook:** [Decision Trees Implementation](https://colab.research.google.com/github/pruthvik-sheth/CMPE-255-Data-Mining/blob/main/Assignments/Decision-Trees/notebooks/Descision_Trees_from_scratch.ipynb)
- **Video Walkthrough:** [Decision Trees Video Walkthrough](#)
- **Description:** Builds a decision tree from scratch for classification and regression tasks, showcasing splitting criteria like Gini Impurity and Entropy.

---

### Part 2: Library-Based Gradient Boosting Techniques

- **Generalized Implementation:** [GBM Techniques](https://colab.research.google.com/github/pruthvik-sheth/CMPE-255-Data-Mining/blob/main/Assignments/Decision-Trees/notebooks/GBM_Techniques.ipynb)

#### 5a. Gradient Boosting Classifiers

- **Video Walkthrough:** [GBM Classifiers Video Walkthrough](#)
- **Description:** Demonstrates the use of XGBoost, CatBoost, LightGBM, Random Forest, AdaBoost, and Decision Tree Classifiers for binary and multi-class classification tasks.

#### 5b. Gradient Boosting Regressors

- **Video Walkthrough:** [GBM Regression Video Walkthrough](#)
- **Description:** Compares XGBoost, CatBoost, and LightGBM for regression tasks, evaluating performance metrics like RMSE and MAE.

#### 5c. Gradient Boosting Ranking Techniques

- **Video Walkthrough:** [GBM Ranking Video Walkthrough](#)
- **Description:** Explores XGBoost, CatBoost, and LightGBM for ranking tasks with a focus on datasets requiring ordinal predictions.
